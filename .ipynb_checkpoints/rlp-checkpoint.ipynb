{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd844c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a73d6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'CartPole-v0'\n",
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56713f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CartPole-v0'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a1b977",
   "metadata": {},
   "source": [
    "# <span style=\"color:black\">Understanding Environment</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5edbcb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states [ 0.01179988  0.16834831 -0.00921419 -0.280191  ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.01516685 -0.02664099 -0.01481801  0.00957161]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.01463403  0.16869031 -0.01462657 -0.2877495 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.01800784  0.36401775 -0.02038156 -0.5850094 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.02528819  0.16918714 -0.03208175 -0.29881594]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.02867194  0.36475137 -0.03805807 -0.60144174]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.03596696  0.56038445 -0.0500869  -0.90586525]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.04717465  0.36597517 -0.06820421 -0.6293364 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.05449415  0.5619793  -0.08079094 -0.94269556]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.06573374  0.75809145 -0.09964485 -1.2596309 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.08089557  0.5643754  -0.12483747 -0.99974537]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.09218308  0.76092476 -0.14483237 -1.3288821 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.10740157  0.9575466  -0.17141002 -1.6631589 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.1265525   0.76478505 -0.2046732  -1.4284021 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.1418482   0.57269317 -0.23324123 -1.2060331 ]\n",
      "reward 1.0\n",
      "done True\n",
      "info {}\n",
      "Episode:1 Score:15.0\n",
      "states [ 0.02397955  0.1647584  -0.03502388 -0.33886424]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.02727471  0.36036074 -0.04180116 -0.64238274]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.03448193  0.16584563 -0.05464882 -0.3631509 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.03779884  0.36169997 -0.06191183 -0.6725526 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.04503284  0.5576254  -0.07536288 -0.9840681 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.05618535  0.7536716  -0.09504425 -1.2994385 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.07125878  0.94986284 -0.12103301 -1.620298  ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.09025604  0.7563569  -0.15343897 -1.3676594 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.10538318  0.56345195 -0.18079217 -1.1266358 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.11665221  0.37109905 -0.20332488 -0.8956729 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.1240742   0.56831086 -0.22123834 -1.2447634 ]\n",
      "reward 1.0\n",
      "done True\n",
      "info {}\n",
      "Episode:2 Score:11.0\n",
      "states [-0.04744762 -0.22619823 -0.03945421  0.2790571 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.05197158 -0.0305363  -0.03387307 -0.02580394]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.05258231 -0.22515652 -0.03438915  0.25600216]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.05708544 -0.41977105 -0.02926911  0.5376429 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.06548086 -0.22425006 -0.01851625  0.23588318]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.06996586 -0.41910264 -0.01379859  0.5226685 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.07834791 -0.22378923 -0.00334522  0.22566958]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.0828237  -0.02861962  0.00116818 -0.06806667]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-8.3396092e-02  1.6648556e-01 -1.9315782e-04 -3.6038080e-01]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.08006638  0.36161026 -0.00740077 -0.65312463]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.07283418  0.55683446 -0.02046327 -0.94812876]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.06169749  0.36199394 -0.03942584 -0.6619449 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.05445761  0.5576416  -0.05266474 -0.9667766 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.04330477  0.363265   -0.07200027 -0.69109213]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.03603948  0.55930823 -0.08582211 -1.0055449 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.02485331  0.7554649  -0.10593301 -1.3238978 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.00974401  0.9517534  -0.13241097 -1.6477661 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.00929106  1.148152   -0.16536629 -1.9786004 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.0322541   0.9551127  -0.20493829 -1.741388  ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.05135635  1.1518937  -0.23976606 -2.0902135 ]\n",
      "reward 1.0\n",
      "done True\n",
      "info {}\n",
      "Episode:3 Score:20.0\n",
      "states [-0.01364388 -0.24027435 -0.02060943  0.28990346]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.01844937 -0.43509647 -0.01481136  0.57601583]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.0271513  -0.6300077  -0.00329105  0.8639962 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.03975145 -0.8250847   0.01398888  1.1556425 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.05625315 -0.6301479   0.03710173  0.86737853]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.06885611 -0.4355499   0.0544493   0.58658785]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.0775671  -0.24123114  0.06618106  0.3115419 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.08239172 -0.43723047  0.07241189  0.6243403 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.09113634 -0.2431902   0.0848987   0.35531312]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.09600013 -0.0493715   0.09200496  0.09056244]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.09698757 -0.24568352  0.09381621  0.41079634]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.10190124 -0.44200158  0.10203213  0.73152   ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.11074127 -0.63837445  0.11666253  1.0544927 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.12350876 -0.4449759   0.13775238  0.8005879 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.13240828 -0.25198504  0.15376414  0.5542151 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.13744798 -0.05931849  0.16484845  0.31365377]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.13863435  0.13311845  0.17112152  0.07715782]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.13597198  0.32542685  0.17266469 -0.15702707]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.12946343  0.51771027  0.16952415 -0.3906519 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.11910924  0.7100718   0.1617111  -0.6254563 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.1049078   0.513106    0.14920197 -0.28652602]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.09464568  0.3162061   0.14347145  0.04924524]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.08832156  0.5090105   0.14445636 -0.19495392]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.07814135  0.7018025   0.14055729 -0.43880713]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.06410529  0.5050001   0.13178115 -0.10532695]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.0540053   0.6980115   0.1296746  -0.35370216]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.04004506  0.5013071   0.12260056 -0.0231052 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.03001892  0.30465966  0.12213846  0.30560616]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.02392573  0.4978486   0.12825058  0.05380101]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.01396876  0.69092065  0.1293266  -0.19582611]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-1.5034586e-04  8.8397831e-01  1.2541008e-01 -4.4507819e-01]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.01752922  1.0771236   0.11650851 -0.6957468 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.03907169  0.880595    0.10259358 -0.3687764 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.05668359  1.074121    0.09521805 -0.62742937]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.07816602  0.8778081   0.08266946 -0.30634207]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.09572218  1.0716606   0.07654262 -0.5718507 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.11715539  1.2656306   0.0651056  -0.8394721 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.142468    1.4598061   0.04831616 -1.1109908 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.17166412  1.6542611   0.02609635 -1.3881335 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.20474935  1.4588239  -0.00166632 -1.087406  ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.23392582  1.263724   -0.02341444 -0.7952464 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.2592003   1.4591593  -0.03931937 -1.0952023 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.28838348  1.6547765  -0.06122342 -1.3999581 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.32147902  1.8506036  -0.08922258 -1.7111369 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.3584911   2.04663    -0.12344532 -2.0302036 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.3994237   1.8529801  -0.16404939 -1.7781401 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.4364833   2.0495255  -0.19961219 -2.1170144 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.4774738   1.856878   -0.24195248 -1.8920782 ]\n",
      "reward 1.0\n",
      "done True\n",
      "info {}\n",
      "Episode:4 Score:48.0\n",
      "states [-0.02039123  0.23860168 -0.00426432 -0.32820228]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.0156192   0.0435407  -0.01082837 -0.03686717]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.01474838  0.23881625 -0.01156571 -0.33294678]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states [-0.00997206  0.04386081 -0.01822465 -0.04393343]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.00909484  0.23923929 -0.01910331 -0.34231022]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.00431006  0.43462774 -0.02594952 -0.64095545]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.0043825   0.6301017  -0.03876863 -0.9416959 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.01698453  0.435523   -0.05760255 -0.6614424 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.02569499  0.24124786 -0.0708314  -0.3874388 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.03051995  0.0471991  -0.07858017 -0.11790252]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.03146393  0.24335386 -0.08093822 -0.43430552]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.03633101  0.43952283 -0.08962433 -0.75136554]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.04512146  0.24574363 -0.10465164 -0.48817766]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.05003634  0.05224182 -0.11441519 -0.23022434]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.05108117 -0.14107507 -0.11901968  0.02429033]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.04825967 -0.3343069  -0.11853387  0.27717832]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.04157353 -0.5275559  -0.11299031  0.5302504 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.03102241 -0.72092223 -0.1023853   0.7853018 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.01660397 -0.9144996  -0.08667926  1.0440986 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.00168602 -0.7183404  -0.06579729  0.7255126 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.01605283 -0.5223733  -0.05128704  0.4128676 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.0265003  -0.71673214 -0.04302969  0.6889508 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.04083494 -0.52104026 -0.02925067  0.38303784]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.05125574 -0.71573496 -0.02158992  0.66635644]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.06557044 -0.5203195  -0.00826279  0.36695462]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.07597683 -0.3250811  -0.00092369  0.07167782]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.08247846 -0.12994593  0.00050986 -0.2212964 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.08507738  0.06516873 -0.00391607 -0.51381844]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.083774    0.2603456  -0.01419243 -0.8077329 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.07856709  0.45565918 -0.03034709 -1.1048461 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.0694539   0.6511668  -0.05244401 -1.4068931 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.05643057  0.45673344 -0.08058188 -1.1310556 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.0472959   0.6528126  -0.10320299 -1.4478854 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.03423965  0.4591     -0.1321607  -1.1891503 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.02505765  0.6556638  -0.1559437  -1.5201671 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [-0.01194437  0.8522889  -0.18634705 -1.8571876 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n",
      "states [ 0.00510141  0.6596384  -0.2234908  -1.6276844 ]\n",
      "reward 1.0\n",
      "done True\n",
      "info {}\n",
      "Episode:5 Score:37.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action =  env.action_space.sample()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        print(\"states\", n_state)\n",
    "        print(\"reward\", reward)\n",
    "        print(\"done\", done)\n",
    "        print(\"info\", info)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e66ce271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04423111,  0.02777795,  0.00073096, -0.03862366], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d31145c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    print(episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4758dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33fdeab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6043299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
